{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d9471a-a6a6-4bba-b32d-c2684dd0772f",
   "metadata": {},
   "source": [
    "# Inference with the PyTorch implementation\n",
    "\n",
    "**Note: `aenet-python` needs to be installed with the `[torch]` requirements (`pip install aenet[torch]`) for this notebook to work.**\n",
    "\n",
    "Predicting energies and forces with the PyTorch API is nearly identical to the Fortran/Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89d4bae-5d85-4aea-b7bb-73207cc57b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "PredictOut with 1 structure(s)  \n",
       "  Structure 0: 23 atoms, E_tot = -19516.791 eV = -848.556 eV/atom  \n"
      ],
      "text/plain": [
       "<aenet.io.predict.PredictOut at 0x13cf90a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aenet.torch_training.trainer import TorchANNPotential\n",
    "\n",
    "pot = TorchANNPotential.from_file('pt-TiO2/Ti-O.pt')\n",
    "# 'cpu' is the default devide. Send to GPU by explicitly specifying\n",
    "# pot = TorchANNPotential.from_file('pt-TiO2/Ti-O.pt', device='cuda')\n",
    "\n",
    "results = pot.predict(\n",
    "    ['xsf-TiO2/structure-001.xsf'],\n",
    "    eval_forces=True\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11f5d3c-3be9-482e-8cf4-73becbb14353",
   "metadata": {},
   "source": [
    "Various predicted properties, including the total and cohesive energy, can be accessed via the `PredictOut` class.  Computation of the forces is optional and has to be requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b691d84d-68e6-4d3e-ae41-d7d4658ed9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mType:\u001b[39m        PredictOut\n",
       "\u001b[31mString form:\u001b[39m\n",
       "PredictOut with 1 structure(s)\n",
       "  Structure 0: 23 atoms, E_tot = -19516.791 eV = -848.556 eV/atom\n",
       "\u001b[31mFile:\u001b[39m        ~/Documents/Cline/aenet-python/src/aenet/io/predict.py\n",
       "\u001b[31mDocstring:\u001b[39m  \n",
       "Parser and representation of output files generated by 'predict.x'.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coords : List[np.ndarray]\n",
       "    Cartesian coordinates for each structure.\n",
       "forces : List[np.ndarray]\n",
       "    Atomic forces for each structure (if computed).\n",
       "atom_types : List[np.ndarray]\n",
       "    Atomic species symbols for each structure.\n",
       "atom_energies : List[np.ndarray]\n",
       "    Atomic energies for each structure (if computed).\n",
       "cohesive_energy : List[float]\n",
       "    Cohesive energies in eV/atom for each structure.\n",
       "total_energy : List[float]\n",
       "    Total energies in eV for each structure.\n",
       "inputs : PredictIn or None\n",
       "    Associated input configuration if predict_in_path was provided."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff69b6-93df-4430-b79c-abeee46271ff",
   "metadata": {},
   "source": [
    "The atom energies are also only returned when they are requested.  As for the Fortran API, this and other options can be set using `PredictionConfig` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67752c49-2746-4a56-bfef-d09a293ff987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.71563512, -0.71347665, -0.74569544, -0.74239586, -0.73947   ,\n",
      "       -0.77258344, -0.69833605, -0.72072413, -0.15845261, -0.17792292,\n",
      "        0.06419335, -0.13566747, -0.14608   , -0.1394532 , -0.16032179,\n",
      "       -0.16988787, -0.14831708, -0.14311656, -0.16197844, -0.16550643,\n",
      "       -0.16633298, -0.17048792, -0.16349779])]\n"
     ]
    }
   ],
   "source": [
    "from aenet.mlip import PredictionConfig\n",
    "from aenet.torch_training.trainer import TorchANNPotential\n",
    "\n",
    "pot = TorchANNPotential.from_file('pt-TiO2/Ti-O.pt')\n",
    "\n",
    "results = pot.predict(\n",
    "    ['xsf-TiO2/structure-001.xsf'],\n",
    "    eval_forces=True,\n",
    "    config=PredictionConfig(\n",
    "        print_atomic_energies=True,\n",
    "        timing=True\n",
    "    )\n",
    ")\n",
    "\n",
    "print(results.atom_energies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4049ef-4350-41d5-a313-a7373e08ad61",
   "metadata": {},
   "source": [
    "We also requested timing information (all values in seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62ec8be-c985-44fd-9093-ba524ecd49c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featurization': [0.0],\n",
       " 'energy_eval': [0.00020122528076171875],\n",
       " 'force_eval': [0.0046880245208740234],\n",
       " 'total': [0.004979133605957031]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe28ecd-6387-40b6-b7ee-310ac204e31e",
   "metadata": {},
   "source": [
    "## Processing large numbers of structures\n",
    "\n",
    "For larger number of structures, `TorchANNPotential` implements batch-processing and parallelization with PyTorch workers.  Per default, the batch size is set to 32, but it can be adjusted via a config option.\n",
    "\n",
    "- `num_workers` (int): Number of DataLoader workers. Default: 0\n",
    "- `prefetch_factor` (int): Number of batches to prefetch per worker. Default: 2\n",
    "- `persistent_workers` (bool): Whether to keep DataLoader workers alive between epochs. Default: True\n",
    "\n",
    "**Note: Don't expect these parameters to have a huge impact on CPUs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dbfd698-7f1c-4162-958c-1ebebc3f1b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from aenet.mlip import PredictionConfig\n",
    "from aenet.torch_training.trainer import TorchANNPotential\n",
    "\n",
    "# this time we load all 100 structures\n",
    "xsf_files = glob.glob('./xsf-TiO2/*.xsf')\n",
    "pot = TorchANNPotential.from_file('pt-TiO2/Ti-O.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07dadb3e-7094-4a9f-8388-aae819e51f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 494 ms, sys: 189 ms, total: 684 ms\n",
      "Wall time: 8.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# parameters optimized for a 2021 M1 MacBook Pro\n",
    "# with 4 performance and 4 efficiency cores\n",
    "cfg = PredictionConfig(\n",
    "    batch_size=4,\n",
    "    num_workers=3,\n",
    "    prefetch_factor=2,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "results = pot.predict(\n",
    "    xsf_files,\n",
    "    eval_forces=True,\n",
    "    config=cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8928a855-5e1c-4127-a523-98c513992cb6",
   "metadata": {},
   "source": [
    "Let's compare this with the default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82667808-05eb-44cd-89b8-7cdf6da06e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 1.95 s, total: 15.8 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = pot.predict(\n",
    "    xsf_files,\n",
    "    eval_forces=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ecb09-93f8-451c-b55a-fadd227b90a5",
   "metadata": {},
   "source": [
    "On our reference laptop, the spead-up is about a factor of two for this small data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58b27a-d2fb-4f00-9702-bee15cd93c52",
   "metadata": {},
   "source": [
    "## Comparison with inference from aenet-Fortran\n",
    "\n",
    "On CPUs, the Fortran-based compiled aenet tools are significantly more efficient.\n",
    "\n",
    "**Note: the following cell requires aenet's Fortran tool's to be correctly installed and configured for use with Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a96aca-e69b-49dd-9b99-bbcb11234ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from aenet.mlip import PredictionConfig, ANNPotential\n",
    "from aenet.torch_training.trainer import TorchANNPotential\n",
    "\n",
    "# load PyTorch model and save it in the \n",
    "# Fortran-compatible ASCII format\n",
    "torch_pot = TorchANNPotential.from_file('pt-TiO2/Ti-O.pt')\n",
    "torch_pot.to_aenet_ascii('./pt-TiO2/')\n",
    "\n",
    "# load all 100 structures again\n",
    "xsf_files = glob.glob('./xsf-TiO2/*.xsf')\n",
    "fort_pot = ANNPotential.from_files(\n",
    "    {'Ti': './pt-TiO2/potential.Ti.nn.ascii',\n",
    "     'O': './pt-TiO2/potential.O.nn.ascii'},\n",
    "    potential_format='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbad2d44-f420-49ea-a84b-489c7992e6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 2 s, total: 15.9 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch_results = torch_pot.predict(\n",
    "    xsf_files,\n",
    "    eval_forces=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641ddf31-3c2d-40dd-a0b1-71cb5d6c907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.41 ms, sys: 13.8 ms, total: 22.2 ms\n",
      "Wall time: 788 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fort_results = fort_pot.predict(\n",
    "    xsf_files,\n",
    "    eval_forces=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8e09e-b966-4dfb-b2ca-25d370eef553",
   "metadata": {},
   "source": [
    "On our test machine (2021 MacBook Pro), Fortran is around 20 times faster than PyTorch for this small dataset.\n",
    "\n",
    "The results are, of course, (numerically) identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeab581e-353c-432b-b7fe-2cd2f132259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference: 1.679e-10 ± 2.988e-09 eV/structure\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "diff = np.array(torch_results.total_energy) - np.array(fort_results.total_energy)\n",
    "print(\"Difference: {:.3e} ± {:.3e} eV/structure\".format(diff.mean(), diff.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
