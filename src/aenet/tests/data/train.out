 ======================================================================
                       Training process started.                       
 ======================================================================
                                                                       
                          2025-11-02  19:21:28                         
                                                                       

 Copyright (C) 2015-2025 Nongnuch Artrith and Alexander Urban

 This program is distributed in the hope that it will be useful, but
 WITHOUT ANY WARRANTY; without even the implied warranty of
 MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 Mozilla Public License, v. 2.0, for more details.

 ----------------------------------------------------------------------
                       Training set normalization                      
 ----------------------------------------------------------------------

 The training set will be normalized now.  Depending on its size this
 process can take a while.  The normalized data set will be written to
 another file. Load that file in future to avoid this step.

 Name of the new training set file: data.train.scaled

 The network output energy will be normalized to the interval [-1,1].
   Energy scaling factor: f = 0.371193
   Atomic energy shift  : s = -5.843924

 Training set normalization done.

 ----------------------------------------------------------------------
                                Networks                               
 ----------------------------------------------------------------------

 Creating a new Ti network

 Number of layers :   4

 Number of nodes (without bias) 
 and activation type per layer :

       1 :    30
       2 :    10  hyperbolic tangent (tanh)
       3 :    10  hyperbolic tangent (tanh)
       4 :     1  linear function (linear)

 Required memory (words) :      65443 (    511.27 KB)

 Total number of weights (incl. bias) :      431

 Creating a new O network

 Number of layers :   4

 Number of nodes (without bias) 
 and activation type per layer :

       1 :    30
       2 :    10  hyperbolic tangent (tanh)
       3 :    10  hyperbolic tangent (tanh)
       4 :     1  linear function (linear)

 Required memory (words) :      65443 (    511.27 KB)

 Total number of weights (incl. bias) :      431

 ----------------------------------------------------------------------
                            Storing networks                           
 ----------------------------------------------------------------------

 Saving the Ti network to file : Ti.nn
 Saving the O network to file : O.nn

 ----------------------------------------------------------------------
                           Training set info.                          
 ----------------------------------------------------------------------

 Training set file                   : data.train.scaled
 Number of structures in the data set: 100

 Atomic species in training set      : 2
   Species : Ti O

 Average energy (eV/atom) : -0.744683
 Minimum energy (eV/atom) : -1.000000
 Maximum energy (eV/atom) : 1.000000

 The input and output values have been normalized to [-1.0, 1.0].
 Structures outside of this interval will not be used for training.
   Energy scaling factor: 0.371193
   Atomic energy shift  : -5.843924

 ----------------------------------------------------------------------
                            Training details                           
 ----------------------------------------------------------------------

 Training method         : Adaptive Moment Estimation (Adam)

 Number of iterations    : 10

 Training structures     : 90
 Testing  structures     : 10

 Testing set : 

       1       28       31       41       85       88       97       98 
      99      100 

 ----------------------------------------------------------------------
                            Training process                           
 ----------------------------------------------------------------------

 Weight optimization for 10 epochs using the Adaptive Moment Estimation (Adam) method.

 Sampling type               : random
 Learning rate               : 1.000E-03
 Gradient decay rate (b1)    : 0.9000
 Sq. gradient decay rate (b1): 0.9990
 Epsilon                     : 1.000E-08
 Sample size                 : 90 (90)
 Mini-batch size             : 8 (8)

        |------------TRAIN-----------|  |------------TEST------------|
 epoch             MAE          <RMSE>             MAE          <RMSE>
     0    2.150739E+00    2.346867E+00    2.653921E+00    2.718389E+00 <
     1    1.922196E+00    2.093266E+00    2.374289E+00    2.430859E+00 <
     2    1.714063E+00    1.860964E+00    2.108215E+00    2.154571E+00 <
     3    1.522756E+00    1.640675E+00    1.870729E+00    1.902153E+00 <
     4    1.351777E+00    1.455192E+00    1.668822E+00    1.694191E+00 <
     5    1.193034E+00    1.293123E+00    1.483568E+00    1.508609E+00 <
     6    1.039895E+00    1.133824E+00    1.290376E+00    1.314003E+00 <
     7    8.939513E-01    9.809784E-01    1.101734E+00    1.122379E+00 <
     8    7.625423E-01    8.457167E-01    9.209569E-01    9.458146E-01 <
     9    6.422894E-01    7.211370E-01    7.440233E-01    7.689421E-01 <
    10    5.355827E-01    6.168381E-01    6.015781E-01    6.244984E-01 <

 Training finished.

 ----------------------------------------------------------------------
                         Storing final energies                        
 ----------------------------------------------------------------------

 Energies of training structures : energies.train.PROCESS
 Energies of testing structures  : energies.test.PROCESS
 (Manually concatenate the files from different processes.)

 Final MAE of training set  =    535.6 meV/atom
 Final MAE of testing set   =    601.6 meV/atom

 Final RMSE of training set =    616.8 meV/atom
 Final RMSE of testing set  =    624.5 meV/atom

 ----------------------------------------------------------------------
                            Storing networks                           
 ----------------------------------------------------------------------

 Saving the Ti network to file : Ti.nn
 Saving the O network to file : O.nn

                                                                       
                          2025-11-02  19:21:29                         
                                                                       
 ======================================================================
                     Neural Network training done.                     
 ======================================================================
