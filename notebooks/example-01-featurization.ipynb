{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurize structures using aenet from Python\n",
    "\n",
    "**Note: Examples 1 & 2 require the ænet executables to be set up correctly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import aenet.io.structure\n",
    "from aenet.featurize import AenetAUCFeaturizer\n",
    "from aenet.trainset import TrnSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "\n",
    "This example shows how to quickly featurize an atomic structure that may or may not be labeled with an energy and atomic forces.\n",
    "\n",
    "First, we read an atomic structure from a file.  This can be in any of the supported structure formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "struc = aenet.io.structure.read('water.xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we configure the featurizer.  The atom type are taken from the structure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fzer = AenetAUCFeaturizer(struc.typenames,\n",
    "                          rad_cutoff=4.0, rad_order=10,\n",
    "                          ang_cutoff=1.5, ang_order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A featurized version of the structure can then be obtained with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized_structure = fzer.featurize_structure(struc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a similar method named `featurize_structures()` (with an additional **s**) that can be used to featurize a list of structures.\n",
    "\n",
    "The featurized structure includes the atom-site feature vectors.  For example, the following yields the feature vector of the first atomic site (starting with 0), which is the oxygen atom of the water molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.73009825, -0.90147023, -0.79067349,  1.72543339, -1.00740569,\n",
       "        -0.67561297,  1.71146394, -1.10790861, -0.55690914,  1.68826525,\n",
       "        -1.20243702,  0.0835817 , -0.02038995, -0.07363335,  0.05631601,\n",
       "         1.73009825, -0.90147023, -0.79067349,  1.72543339, -1.00740569,\n",
       "        -0.67561297,  1.71146394, -1.10790861, -0.55690914,  1.68826525,\n",
       "        -1.20243702,  0.0835817 , -0.02038995, -0.07363335,  0.05631601],\n",
       "       [ 1.55242929, -0.61883393, -1.00049978,  1.32680075, -0.12552333,\n",
       "        -0.98685814,  0.79500362,  0.12479959, -0.54970475,  0.29804719,\n",
       "        -0.06287795,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.17766897,  0.28263629, -0.20982628, -0.39863264,  0.88188236,\n",
       "        -0.31124517, -0.91646032,  1.2327082 ,  0.00720439, -1.39021806,\n",
       "         1.13955907,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.55242929, -0.61883393, -1.00049978,  1.32680075, -0.12552333,\n",
       "        -0.98685814,  0.79500362,  0.12479959, -0.54970475,  0.29804719,\n",
       "        -0.06287795,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.17766897,  0.28263629, -0.20982628, -0.39863264,  0.88188236,\n",
       "        -0.31124517, -0.91646032,  1.2327082 ,  0.00720439, -1.39021806,\n",
       "         1.13955907,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurized_structure.atom_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature vector for the entire structure can be computed with the moment-expansion approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.64126377 -0.76015208 -0.89558663  1.52611707 -0.56646451 -0.83123556\n",
      "  1.25323378 -0.49155451 -0.55330694  0.99315622 -0.63265748  0.04179085\n",
      " -0.01019498 -0.03681667  0.02815801  0.77621464 -0.30941697 -0.50024989\n",
      "  0.66340037 -0.06276166 -0.49342907  0.39750181  0.06239979 -0.27485237\n",
      "  0.1490236  -0.03143897  0.04179085 -0.01019498 -0.03681667  0.02815801\n",
      " -0.08883448  0.14131815 -0.10491314 -0.19931632  0.44094118 -0.15562259\n",
      " -0.45823016  0.6163541   0.0036022  -0.69510903  0.56977954 -0.04179085\n",
      "  0.01019498  0.03681667 -0.02815801 -0.95388361  0.59205326  0.29042361\n",
      " -1.06203301  0.94464402  0.1821839  -1.31396213  1.1703084   0.28205677\n",
      " -1.53924166  1.17099805 -0.04179085  0.01019498  0.03681667 -0.02815801]\n"
     ]
    }
   ],
   "source": [
    "print(featurized_structure.global_moment_fingerprint(outer_moment=1, inner_moment=1, \n",
    "                                                     weighted=True, append_weighted=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "This example dives a bit deeper and shows a workflow that is applicable to large structure databases.\n",
    "Here, we assume that a set of atomic structures in XSF format is already available in `./xsf/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the AUC featurizer uses the Chebyshev method (Artrith 2017)\n",
    "fzer = AenetAUCFeaturizer(['Li', 'Mo', 'Ni', 'Ti', 'O'],\n",
    "                          rad_cutoff=4.0, rad_order=10, \n",
    "                          ang_cutoff=1.5, ang_order=3)\n",
    "\n",
    "# aenet's generate.x will be run in the specified subdirectory ('run').\n",
    "# If no work directory is given, a temporary directory is created and\n",
    "# removed after completion.\n",
    "fzer.run_aenet_generate(glob.glob(\"./xsf/*.xsf\"), \n",
    "                        atomic_energies={\n",
    "                            'Li': -2.5197301758568920,\n",
    "                            'Mo': -0.6299325439642232,\n",
    "                            'Ni': -2.2047639038747695,\n",
    "                            'O': -10.0789207034275830,\n",
    "                            'Ti': -2.2047639038747695},\n",
    "                        workdir='run')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above creates the files `generate.out` and `features.h5` containing the output written by `generate.x` and the data set in HDF5 format, respectively.  Since we specified the work directory `run` above, this directory is also kept with all files used to run `generate.x`.\n",
    "\n",
    "To access the featurized structures, the data set can be read with the `TrnSet` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set info:\n",
      "  Name           : run/data.train\n",
      "  Atom types     : Li Mo Ni Ti O\n",
      "  Atomic energies: -2.520 -0.630 -2.205 -2.205 -10.079\n",
      "  #atom, #struc. : 46144 824\n",
      "  E_min, max, av : -4.587 -4.548 -4.568\n",
      "  File (format)  : features.h5 (hdf5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with TrnSet.from_file('features.h5') as ts:\n",
    "    print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information for each atomic structure (including the atomic features) can be accessed with `ts.read_structure(i)` where `i` is the index of the structure.  However, for large data sets it is more efficient to access all structures sequentially.  This can be done using the method `ts.read_next_structure()` or by iterating over the training set object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few structures:\n",
      "  0: /Users/aurban/Documents/Cline/aenet-python/notebooks/xsf/structure466.xsf (56 atoms)\n",
      "  1: /Users/aurban/Documents/Cline/aenet-python/notebooks/xsf/structure300.xsf (56 atoms)\n",
      "  2: /Users/aurban/Documents/Cline/aenet-python/notebooks/xsf/structure314.xsf (56 atoms)\n"
     ]
    }
   ],
   "source": [
    "with TrnSet.from_file('features.h5') as ts:\n",
    "    print(\"\\nFirst few structures:\")\n",
    "    for i, s in enumerate(ts):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        print(f\"  {i}: {s.path} ({s.num_atoms} atoms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: PyTorch-based Featurization (No Fortran Required)\n",
    "\n",
    "The `TorchAUCFeaturizer` provides a pure Python/PyTorch implementation that is a drop-in replacement for `AenetAUCFeaturizer`.\n",
    "\n",
    "**Note: The `TorchAUCFeaturizer` does not require the ænet binaries to be installed.**\n",
    "\n",
    "Simply replace `AenetAUCFeaturizer` with `TorchAUCFeaturizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from aenet.torch_featurize import TorchAUCFeaturizer\n",
    "from aenet.trainset import TrnSet\n",
    "import aenet.io.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.73009825, -0.90147023, -0.79067349,  1.72543339, -1.00740569,\n",
       "        -0.67561297,  1.71146394, -1.10790861, -0.55690914,  1.68826525,\n",
       "        -1.20243702,  0.0835817 , -0.02038995, -0.07363335,  0.05631601,\n",
       "         1.73009825, -0.90147023, -0.79067349,  1.72543339, -1.00740569,\n",
       "        -0.67561297,  1.71146394, -1.10790861, -0.55690914,  1.68826525,\n",
       "        -1.20243702,  0.0835817 , -0.02038995, -0.07363335,  0.05631601],\n",
       "       [ 1.55242929, -0.61883393, -1.00049978,  1.32680075, -0.12552333,\n",
       "        -0.98685814,  0.79500362,  0.12479959, -0.54970475,  0.29804719,\n",
       "        -0.06287795,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.17766897,  0.28263629, -0.20982628, -0.39863264,  0.88188236,\n",
       "        -0.31124517, -0.91646032,  1.2327082 ,  0.00720439, -1.39021806,\n",
       "         1.13955907,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.55242929, -0.61883393, -1.00049978,  1.32680075, -0.12552333,\n",
       "        -0.98685814,  0.79500362,  0.12479959, -0.54970475,  0.29804719,\n",
       "        -0.06287795,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.17766897,  0.28263629, -0.20982628, -0.39863264,  0.88188236,\n",
       "        -0.31124517, -0.91646032,  1.2327082 ,  0.00720439, -1.39021806,\n",
       "         1.13955907,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struc = aenet.io.structure.read('water.xyz')\n",
    "fzer = TorchAUCFeaturizer(struc.typenames,\n",
    "                          rad_cutoff=4.0, rad_order=10,\n",
    "                          ang_cutoff=1.5, ang_order=3)\n",
    "featurized_structure = fzer.featurize_structure(struc)\n",
    "featurized_structure.atom_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyTorch implementation produces identical HDF5 files without requiring Fortran executables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 824 structure files...\n",
      "  Read 100/824 structures\n",
      "  Read 200/824 structures\n",
      "  Read 300/824 structures\n",
      "  Read 400/824 structures\n",
      "  Read 500/824 structures\n",
      "  Read 600/824 structures\n",
      "  Read 700/824 structures\n",
      "  Read 800/824 structures\n",
      "Featurizing 824 structures...\n",
      "  Featurized 100/824 structures\n",
      "  Featurized 200/824 structures\n",
      "  Featurized 300/824 structures\n",
      "  Featurized 400/824 structures\n",
      "  Featurized 500/824 structures\n",
      "  Featurized 600/824 structures\n",
      "  Featurized 700/824 structures\n",
      "  Featurized 800/824 structures\n",
      "Writing features to features_torch.h5...\n",
      "Done! Features written to features_torch.h5\n"
     ]
    }
   ],
   "source": [
    "# Same API as AenetAUCFeaturizer!\n",
    "torch_fzer = TorchAUCFeaturizer(['Li', 'Mo', 'Ni', 'Ti', 'O'],\n",
    "                                rad_cutoff=4.0, rad_order=10,\n",
    "                                ang_cutoff=1.5, ang_order=3)\n",
    "\n",
    "# Generate features (no Fortran executables needed)\n",
    "torch_fzer.run_aenet_generate(glob.glob(\"./xsf/*.xsf\"),\n",
    "                              hdf5_filename='features_torch.h5',\n",
    "                              atomic_energies={\n",
    "                                  'Li': -2.5197301758568920,\n",
    "                                  'Mo': -0.6299325439642232,\n",
    "                                  'Ni': -2.2047639038747695,\n",
    "                                  'O': -10.0789207034275830,\n",
    "                                  'Ti': -2.2047639038747695})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 Format Compatibility\n",
    "\n",
    "The PyTorch-generated HDF5 files are fully compatible with the Fortran version. You can read them with `TrnSet` exactly the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set info:\n",
      "  Name           : PyTorch-generated training set\n",
      "  Atom types     : Li Mo Ni Ti O\n",
      "  Atomic energies: -2.520 -0.630 -2.205 -2.205 -10.079\n",
      "  #atom, #struc. : 46144 824\n",
      "  E_min, max, av : -4.587 -4.548 -4.568\n",
      "  File (format)  : features_torch.h5 (hdf5)\n",
      "\n",
      "\n",
      "First few structures:\n",
      "  0: /Users/aurban/Documents/Cline/aenet-python/notebooks/xsf/structure466.xsf (56 atoms)\n",
      "  1: /Users/aurban/Documents/Cline/aenet-python/notebooks/xsf/structure300.xsf (56 atoms)\n",
      "  2: /Users/aurban/Documents/Cline/aenet-python/notebooks/xsf/structure314.xsf (56 atoms)\n"
     ]
    }
   ],
   "source": [
    "with TrnSet.from_file('features_torch.h5') as ts:\n",
    "    print(ts)\n",
    "    print(\"\\nFirst few structures:\")\n",
    "    for i, s in enumerate(ts):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        print(f\"  {i}: {s.path} ({s.num_atoms} atoms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Tip: GPU Acceleration\n",
    "\n",
    "For large datasets, you can enable GPU acceleration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available (requires CUDA-enabled PyTorch)\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch_fzer_gpu = TorchAUCFeaturizer(['Li', 'Mo', 'Ni', 'Ti', 'O'],\n",
    "                                    rad_cutoff=4.0, rad_order=10,\n",
    "                                    ang_cutoff=1.5, ang_order=3,\n",
    "                                    device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
